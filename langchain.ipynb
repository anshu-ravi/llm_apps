{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the API Key \n",
    "load_dotenv()\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "hf_key = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature\n",
    "- Directly influences how creative we want the model to be. This implies that the output probability distribution of the all words are altered to give different/more unique results.\n",
    "- A value of 0 implies the model is sticking to its safety and only predicting the next most likely word based on max probability \n",
    "- A value closer to 1 implies the model is getting more creative. However this could also lead to incorrect outputs or gibberish.\n",
    "\n",
    "\n",
    "Default Model: GPT 3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.6, api_key=openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "text = 'What is the capital of India'\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moscow\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "\n",
    "model_kwargs = {\n",
    "    'temperature':0,\n",
    "    'max_length': 64\n",
    "}\n",
    "\n",
    "question = 'Can you tell me the capital of Russia?'\n",
    "flan_model = HuggingFaceHub(repo_id = 'google/flan-t5-large', model_kwargs = model_kwargs, huggingfacehub_api_token=hf_key)\n",
    "flan_output = flan_model.predict(question)\n",
    "print(flan_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me the captial of India\n",
      "arunachal pradesh\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    " \n",
    "capital_pt = PromptTemplate(input_variables=['country'],\n",
    "               template=\"Tell me the captial of {country}\")\n",
    "\n",
    "print(capital_pt.format(country = 'India'))\n",
    "\n",
    "# Create a chain to first get the value for country, add it to the input text using the prompt template and then pass that to the model \n",
    "chain = LLMChain(llm = flan_model, prompt = capital_pt)\n",
    "print(chain.run('India')) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Multiple chains using Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'London Eye'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "capital_chain = LLMChain(llm = flan_model, prompt = capital_pt)\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=['capital'], \n",
    "                                 template = \"Suggest some great places to visit in {capital}\")\n",
    "\n",
    "famous_chain = LLMChain(llm = flan_model, prompt = famous_template)\n",
    "\n",
    "\n",
    "final_chain = SimpleSequentialChain(chains = [capital_chain, famous_chain])\n",
    "final_chain.run('United Kingdom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Chain  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anshu/miniconda3/envs/llm/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country': 'India',\n",
       " 'capital': '\\n\\nThe capital of India is New Delhi.',\n",
       " 'places': \" Some great places to visit in New Delhi are:\\n\\n1. Red Fort: This iconic red sandstone fort was built in the 17th century and is a must-visit for its beautiful architecture and historical significance.\\n\\n2. Qutub Minar: Another popular tourist attraction, the Qutub Minar is a 73-meter tall minaret built in the 12th century. It is a UNESCO World Heritage Site and a great place to learn about Delhi's history.\\n\\n3. India Gate: This war memorial is a popular spot for locals and tourists alike. It is a great place to take a stroll, have a picnic, and admire the beautiful architecture.\\n\\n4. Lotus Temple: This stunning temple, shaped like a lotus flower, is a symbol of peace and unity. It is open to people of all religions and is a great place to meditate and find inner peace.\\n\\n5. Humayun's Tomb: This magnificent tomb is another UNESCO World Heritage Site and is known for its stunning Mughal architecture. It is the final resting place of Mughal Emperor Humayun and is surrounded by beautiful gardens.\\n\\n6. Akshardham Temple: This modern Hindu temple is a popular tourist spot for its stunning architecture, light and sound show, and\"}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chosen_model = llm\n",
    "\n",
    "# Setting up the Template \n",
    "capital_pt = PromptTemplate(input_variables=['country'],\n",
    "               template=\"Tell me the captial of {country}\")\n",
    "famous_template = PromptTemplate(input_variables=['capital'], \n",
    "                                 template = \"Suggest some great places to visit in {capital}\")\n",
    "\n",
    "# Setting up the chain\n",
    "capital_chain = LLMChain(llm = chosen_model, prompt = capital_pt, output_key='capital')\n",
    "famous_chain = LLMChain(llm = chosen_model, prompt = famous_template, output_key='places')\n",
    "chain = SequentialChain(chains = [capital_chain, famous_chain], input_variables = ['country'], output_variables = ['capital', 'places'])\n",
    "\n",
    "# Running the model \n",
    "input_text = {'country': 'India'}\n",
    "chain(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatmodels with ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anshu/miniconda3/envs/llm/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chatbot = ChatOpenAI(api_key=openai_key, \n",
    "                     temperature = 0.6,\n",
    "                     model = 'gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anshu/miniconda3/envs/llm/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Morocco is a country with a rich history, vibrant culture, and diverse landscapes. Some of the best cities to visit in Morocco include:\\n\\n1. Marrakech: Known for its bustling souks, historic medina, and beautiful architecture, Marrakech is a must-visit city in Morocco. Be sure to visit the famous Jemaa el-Fnaa square, the Bahia Palace, and the Majorelle Garden.\\n\\n2. Fes: Fes is one of the oldest and most well-preserved medieval cities in the world. Explore the maze-like streets of the medina, visit the Bou Inania Madrasa, and see the iconic blue pottery of Fes.\\n\\n3. Chefchaouen: This picturesque blue city is nestled in the Rif Mountains and is known for its charming streets, blue-washed buildings, and stunning mountain views. It's a great place to relax and explore at a slower pace.\\n\\n4. Essaouira: This coastal city is a laid-back alternative to the hustle and bustle of Marrakech and Fes. Enjoy fresh seafood, wander through the medina, and relax on the beautiful beaches.\\n\\n5. Casablanca: As Morocco's largest city, Casablanca offers a mix of modern and traditional attractions. Visit the Hassan II Mosque, explore the Corniche waterfront, and experience the city's vibrant nightlife.\\n\\nThese are just a few of the many incredible cities to visit in Morocco. Each city offers its own unique charm and attractions, making Morocco a diverse and exciting destination for travelers.\" response_metadata={'token_usage': {'completion_tokens': 316, 'prompt_tokens': 30, 'total_tokens': 346}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-844c61cc-872e-4b31-8253-468be119cc22-0'\n"
     ]
    }
   ],
   "source": [
    "output = chatbot([\n",
    "    SystemMessage(content = \"You are a travel guide assisstant!\"),\n",
    "    HumanMessage(content = \"What are the best cities to visit in Morocco?\"),\n",
    "])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template + LLM + Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSV(BaseOutputParser):\n",
    "    def parse(self, output):\n",
    "        return output.strip().split(',')\n",
    "    \n",
    "template = \"You are a helpful assisstant. When the user asks for the best cities to visit in a country, only return top 3 cities in that country separated by commas. No other text is needed\"\n",
    "human_template = \"{text}\"\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', template),\n",
    "    ('human', human_template)\n",
    "])\n",
    "\n",
    "chain = chatprompt|chatbot|CSV()\n",
    "new_output = chain.invoke({'text':'What are the best cities to visit in India?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai', ' Delhi', ' Jaipur']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
